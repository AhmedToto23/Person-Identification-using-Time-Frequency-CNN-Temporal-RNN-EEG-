{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOSLdEIPOoN6AdoX0dZsf+2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AhmedToto23/Person-Identification-using-Time-Frequency-CNN-Temporal-RNN-EEG-/blob/main/Cnn_Rnn_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWsmUw4MUGLa",
        "outputId": "e4c4fdf8-e0bb-4cce-8173-50cb1fe5cf87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import AdamW"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths (adjust if needed)\n",
        "SEGMENTS_DIR = \"/content/drive/MyDrive/files/segments\" # where .npy segments are stored\n",
        "META_CSV = os.path.join(SEGMENTS_DIR, 'metadata.csv')\n",
        "MODEL_SAVE = '/content/drive/MyDrive/files/best_cnn_rnn.pth'\n",
        "os.makedirs(SEGMENTS_DIR, exist_ok=True)"
      ],
      "metadata": {
        "id": "OFYN3U5gUdmD"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build metadata if missing\n",
        "if not os.path.exists(META_CSV):\n",
        "    records = []\n",
        "    for f in sorted(glob(os.path.join(SEGMENTS_DIR, '*.npy'))):\n",
        "        fname = os.path.basename(f)\n",
        "        # expected pattern: Sxxx_<orig>_segN.npy\n",
        "        parts = fname.split('_')\n",
        "        if len(parts) < 2:\n",
        "            continue\n",
        "        subj = parts[0]\n",
        "        session = 1\n",
        "        # try to detect session in filename\n",
        "        for p in parts:\n",
        "            if p.lower().startswith('session'):\n",
        "                try:\n",
        "                    session = int(p.replace('session',''))\n",
        "                except:\n",
        "                    session = 1\n",
        "        # subject like S001 -> label 0\n",
        "        label = int(subj.replace('S','')) - 1\n",
        "        records.append({'path': f, 'label': label, 'session': session})\n",
        "    meta = pd.DataFrame.from_records(records)\n",
        "    meta.to_csv(META_CSV, index=False)\n",
        "    print('Created metadata.csv with', len(meta), 'entries')\n",
        "else:\n",
        "    meta = pd.read_csv(META_CSV)\n",
        "    print('Loaded metadata.csv with', len(meta), 'entries')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXPOfLtnUhnA",
        "outputId": "51a0b12d-1b0a-4f07-ad87-f65de3526319"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded metadata.csv with 65737 entries\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset: compute spectrogram per segment on-the-fly\n",
        "class EEGSpectrogramDataset(Dataset):\n",
        "    def __init__(self, meta_df, sample_rate=160, n_fft=256, hop=64, freq_range=(1,50), transform=None):\n",
        "        self.meta = meta_df.reset_index(drop=True)\n",
        "        self.sample_rate = sample_rate\n",
        "        self.n_fft = n_fft\n",
        "        self.hop = hop\n",
        "        self.freq_range = freq_range\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.meta)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.meta.iloc[idx]\n",
        "        arr = np.load(row['path']).astype(np.float32)  # (C, T)\n",
        "        x = torch.from_numpy(arr)\n",
        "        # channel-wise STFT -> magnitude\n",
        "        specs = []\n",
        "        for ch in range(x.shape[0]):\n",
        "            stft = torch.stft(x[ch], n_fft=self.n_fft, hop_length=self.hop, win_length=self.n_fft, center=True, return_complex=True)\n",
        "            mag = stft.abs()\n",
        "            specs.append(mag.unsqueeze(0))\n",
        "        spec = torch.cat(specs, dim=0)  # (C, F, Tfr)\n",
        "        freqs = torch.linspace(0, self.sample_rate / 2, steps=(self.n_fft // 2 + 1))\n",
        "        fmin, fmax = self.freq_range\n",
        "        fmask = (freqs >= fmin) & (freqs <= fmax)\n",
        "        spec = spec[:, fmask, :]\n",
        "        spec = torch.log1p(spec)\n",
        "        label = int(row['label'])\n",
        "        session = int(row['session']) if 'session' in row else 1\n",
        "        if self.transform:\n",
        "            spec = self.transform(spec)\n",
        "        return spec, label, session"
      ],
      "metadata": {
        "id": "SQsrVrADVWBX"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple Hybrid Model\n",
        "# CNN encoder produces timewise features -> GRU processes temporal sequence\n",
        "class CNNEncoder(nn.Module):\n",
        "    def __init__(self, in_ch, cnn_channels=(32,64,128)):\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "        prev = in_ch\n",
        "        for outc in cnn_channels:\n",
        "            layers += [\n",
        "                nn.Conv2d(prev, outc, kernel_size=3, padding=1),\n",
        "                nn.BatchNorm2d(outc),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.MaxPool2d((2,2))\n",
        "            ]\n",
        "            prev = outc\n",
        "        self.net = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class HybridCNNRNN(nn.Module):\n",
        "    def __init__(self, in_ch, n_freq_bins, cnn_channels=(32,64,128), gru_hidden=256, gru_layers=2, n_classes=109, dropout=0.4):\n",
        "        super().__init__()\n",
        "        self.encoder = CNNEncoder(in_ch, cnn_channels=cnn_channels)\n",
        "        # compute feature dim after cnn pooling for freq dimension\n",
        "        # assume freq dimension is divisible by 2**len(cnn_channels)\n",
        "        self.freq_reduction = 2 ** len(cnn_channels)\n",
        "        feat_dim = cnn_channels[-1] * (n_freq_bins // self.freq_reduction)\n",
        "        self.gru = nn.GRU(input_size=feat_dim, hidden_size=gru_hidden, num_layers=gru_layers, batch_first=True, bidirectional=True)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(gru_hidden*2, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(512, n_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (B, C, F, T)\n",
        "        out = self.encoder(x)  # (B, C', F', T')\n",
        "        B, C1, Fp, Tp = out.shape\n",
        "        out = out.permute(0, 3, 1, 2).contiguous()  # (B, Tp, C', F')\n",
        "        out = out.view(B, Tp, C1 * Fp)  # (B, Tp, feat)\n",
        "        gru_out, _ = self.gru(out)\n",
        "        pooled = gru_out.mean(dim=1)\n",
        "        logits = self.classifier(pooled)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "iAiNPIAhVg5D"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train / Eval helpers\n",
        "from sklearn.metrics import accuracy_score, top_k_accuracy_score\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def train_epoch(model, loader, optim, device):\n",
        "    model.train()\n",
        "    losses = []\n",
        "    all_preds, all_labels = [], []\n",
        "    for spec, label, _ in tqdm(loader, desc='train', leave=False):\n",
        "        spec = spec.to(device)\n",
        "        label = label.to(device)\n",
        "        optim.zero_grad()\n",
        "        out = model(spec)\n",
        "        loss = F.cross_entropy(out, label)\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        losses.append(loss.item())\n",
        "        preds = out.argmax(dim=1).cpu().numpy()\n",
        "        all_preds.extend(preds.tolist())\n",
        "        all_labels.extend(label.cpu().numpy().tolist())\n",
        "    return np.mean(losses), accuracy_score(all_labels, all_preds)\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loader, device):\n",
        "    model.eval()\n",
        "    probs_list = []\n",
        "    labels = []\n",
        "    for spec, label, _ in tqdm(loader, desc='eval', leave=False):\n",
        "        spec = spec.to(device)\n",
        "        out = model(spec)\n",
        "        probs = F.softmax(out, dim=1).cpu().numpy()\n",
        "        probs_list.append(probs)\n",
        "        labels.extend(label.numpy().tolist())\n",
        "    probs = np.concatenate(probs_list, axis=0)\n",
        "    preds = probs.argmax(axis=1)\n",
        "    top1 = accuracy_score(labels, preds)\n",
        "    try:\n",
        "        top5 = top_k_accuracy_score(labels, probs, k=5)\n",
        "    except Exception:\n",
        "        top5 = None\n",
        "    return top1, top5\n"
      ],
      "metadata": {
        "id": "85_eImQuVpVv"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare splits, dataloaders\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Perform a random train-test split on the entire metadata\n",
        "train_meta, test_meta = train_test_split(meta, test_size=0.2, random_state=42, stratify=meta['label'])\n",
        "\n",
        "train_meta = train_meta.reset_index(drop=True)\n",
        "test_meta = test_meta.reset_index(drop=True)\n",
        "\n",
        "print(f'Train samples: {len(train_meta)}')\n",
        "print(f'Test samples: {len(test_meta)}')\n",
        "\n",
        "train_ds = EEGSpectrogramDataset(train_meta)\n",
        "test_ds = EEGSpectrogramDataset(test_meta)\n",
        "\n",
        "# quick dimension probe\n",
        "spec0, _, _ = train_ds[0]\n",
        "C, n_freq_bins_val, T = spec0.shape # Renamed F to n_freq_bins_val\n",
        "print('Spec shape per sample:', spec0.shape)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=16, shuffle=True, num_workers=2, pin_memory=True)\n",
        "test_loader = DataLoader(test_ds, batch_size=32, shuffle=False, num_workers=2, pin_memory=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzXe74RbVux2",
        "outputId": "30ffa803-f2cd-4a61-e3be-557e1b09280f"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train samples: 52589\n",
            "Test samples: 13148\n",
            "Spec shape per sample: torch.Size([64, 79, 6])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = HybridCNNRNN(in_ch=C, n_freq_bins=n_freq_bins_val, n_classes=109, cnn_channels=(32,64)).to(device) # Changed F to n_freq_bins_val\n",
        "optim = AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optim, step_size=8, gamma=0.5)\n"
      ],
      "metadata": {
        "id": "coBdaEhpV0Sq"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "best = 0.0\n",
        "epochs = 30\n",
        "for ep in range(1, epochs+1):\n",
        "    loss, train_acc = train_epoch(model, train_loader, optim, device)\n",
        "    top1, top5 = evaluate(model, test_loader, device)\n",
        "    scheduler.step()\n",
        "    print(f'Epoch {ep:02d} loss={loss:.4f} train_acc={train_acc:.3f} test_top1={top1:.3f} test_top5={top5}')\n",
        "    if top1 > best:\n",
        "        best = top1\n",
        "        torch.save(model.state_dict(), MODEL_SAVE)\n",
        "        print('Saved best model ->', MODEL_SAVE)\n",
        "\n",
        "print('Training complete. Best test top1:', best)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0t56ZxVsV9ze",
        "outputId": "e369218b-e714-45e9-8e8f-dffc81218fcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtrain:   0%|          | 0/3287 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "eval:   0%|          | 0/411 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01 loss=1.5594 train_acc=0.550 test_top1=0.207 test_top5=None\n",
            "Saved best model -> /content/drive/MyDrive/files/best_cnn_rnn.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtrain:   0%|          | 0/3287 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "eval:   0%|          | 0/411 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 02 loss=0.3921 train_acc=0.885 test_top1=0.209 test_top5=None\n",
            "Saved best model -> /content/drive/MyDrive/files/best_cnn_rnn.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtrain:   0%|          | 0/3287 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "eval:   0%|          | 0/411 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 03 loss=0.2328 train_acc=0.934 test_top1=0.477 test_top5=None\n",
            "Saved best model -> /content/drive/MyDrive/files/best_cnn_rnn.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtrain:   0%|          | 0/3287 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "eval:   0%|          | 0/411 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 04 loss=0.1758 train_acc=0.950 test_top1=0.651 test_top5=None\n",
            "Saved best model -> /content/drive/MyDrive/files/best_cnn_rnn.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtrain:   0%|          | 0/3287 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "eval:   0%|          | 0/411 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 05 loss=0.1389 train_acc=0.960 test_top1=0.323 test_top5=None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtrain:   0%|          | 0/3287 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "eval:   0%|          | 0/411 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 06 loss=0.1260 train_acc=0.965 test_top1=0.759 test_top5=None\n",
            "Saved best model -> /content/drive/MyDrive/files/best_cnn_rnn.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtrain:   0%|          | 0/3287 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "eval:   0%|          | 0/411 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 07 loss=0.1147 train_acc=0.969 test_top1=0.436 test_top5=None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtrain:   0%|          | 0/3287 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "eval:   0%|          | 0/411 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 08 loss=0.0958 train_acc=0.974 test_top1=0.669 test_top5=None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtrain:   0%|          | 0/3287 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "eval:   0%|          | 0/411 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 09 loss=0.0433 train_acc=0.988 test_top1=0.985 test_top5=None\n",
            "Saved best model -> /content/drive/MyDrive/files/best_cnn_rnn.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtrain:   0%|          | 0/3287 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "eval:   0%|          | 0/411 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 loss=0.0371 train_acc=0.990 test_top1=0.865 test_top5=None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtrain:   0%|          | 0/3287 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "eval:   0%|          | 0/411 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 loss=0.0357 train_acc=0.991 test_top1=0.978 test_top5=None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtrain:   0%|          | 0/3287 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "eval:   0%|          | 0/411 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 loss=0.0273 train_acc=0.992 test_top1=0.905 test_top5=None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtrain:   0%|          | 0/3287 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "train:  55%|█████▍    | 1793/3287 [09:01<06:45,  3.69it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute per-subject accuracy and save a simple report\n",
        "@torch.no_grad()\n",
        "def per_subject_accuracy(model, loader, device, meta_df):\n",
        "    model.eval()\n",
        "    preds = []\n",
        "    labels = []\n",
        "    paths = []\n",
        "    for spec, label, _ in tqdm(loader, desc='per-subject', leave=False):\n",
        "        spec = spec.to(device)\n",
        "        out = model(spec)\n",
        "        p = out.argmax(dim=1).cpu().numpy()\n",
        "        preds.extend(p.tolist())\n",
        "        labels.extend(label.numpy().tolist())\n",
        "    df = pd.DataFrame({'label': labels, 'pred': preds})\n",
        "    accs = df.groupby('label').apply(lambda d: (d['label']==d['pred']).mean())\n",
        "    accs = accs.sort_values()\n",
        "    accs.to_csv(os.path.join(os.path.dirname(MODEL_SAVE), 'per_subject_acc.csv'))\n",
        "    print('Saved per-subject accuracies.')"
      ],
      "metadata": {
        "id": "8AiF7lV7WC1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load best model and run per-subject report\n",
        "model.load_state_dict(torch.load(MODEL_SAVE, map_location=device))\n",
        "per_subject_accuracy(model, test_loader, device, test_meta)\n",
        "print('Report saved near model file.')"
      ],
      "metadata": {
        "id": "xWqx8uyEWHUz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}